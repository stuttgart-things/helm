---
version: 3
vars:
  PROJECT:
    sh: echo ${PROJECT}
  BRANCH:
    sh: if [ $(git rev-parse --abbrev-ref HEAD) != "main" ]; then echo $(git rev-parse --abbrev-ref HEAD); else echo main ; fi
  CROSSPLANE_PACKAGE_REGISTRY: ghcr.io
  DAGGER_CROSSPLANE_MODULE: github.com/stuttgart-things/dagger/crossplane
  DAGGER_CROSSPLANE_MODULE_VERSION: v0.0.2
  TEST_RELEASE_TEMPLATES: tests/releases.yaml
  TEST_DIR: /tmp
  TEST_DEFAULTS: tests/defaults.yaml
  CLUSTER_NAME: helm-dev
  PATH_KUBE_CONFIG: /home/sthings/.kube/kind-{{ .CLUSTER_NAME }}
  PATH_CLUSTER_TEMPLATE: tests/cluster.yaml
  DEV_CLUSTER_DIR: /tmp/helmfiles/cluster
  KIND_CONFIG_PATH: /tmp/kind-config.yaml
  CLUSTER_INFRA_HELMFILE: /tmp/kind-infra.yaml
  TEST_FILES: tests/releases.yaml
  POST_CONFIG_FILES: tests/post-release.yaml

  DATE:
    sh: date +"%Y.%m%d.%H%M"

tasks:
  do:
    desc: Select a task to run
    cmds:
      - |
        task=$(yq e '.tasks | keys' Taskfile.yaml | sed 's/^- //' | gum choose)
        task ${task}

  install-release:
    desc: Test a release
    cmds:
      - rm -rf {{ .TEST_DIR }}/* && mkdir {{ .TEST_DIR }} || true
      - |
        release=$(yq '.template | keys | .[]' {{ .TEST_RELEASE_TEMPLATES }} | gum choose)
        folder=$(find {{ .SEARCH_FOLDERS }} -type f -name "${release}.yaml" -exec dirname {} \; | sort -u)
        domain=$(kubectl get nodes -o json | jq -r '.items[] | select(.metadata.labels."ingress-ready" == "true") | .status.addresses[] | select(.type == "InternalIP") | .address').nip.io
        clusterIssuer=$(kubectl get clusterissuer -o jsonpath='{.items[0].metadata.name}')
        storageClass=standard

        machineshop render \
        --source local \
        --template {{ .TEST_RELEASE_TEMPLATES }} \
        --output file \
        --kind multikey \
        --key ${release} \
        --destination {{ .TEST_DIR }}/${release}.yaml \
        --values "source={{ .USER_WORKING_DIR }}/${folder}/${release}.yaml, domain=${domain}, clusterIssuer=${clusterIssuer}, storageClass=${storageClass}"

        helmfile template -f {{ .TEST_DIR }}/${release}.yaml

        SELECTED_KUBECONFIG=$(gum choose {{ .ALL_KUBECONFIGS }})
        echo SWITCHING TO ${SELECTED_KUBECONFIG//\"/}
        printf "\n\nexport KUBECONFIG={{ .KUBECONFIG_FOLDER }}/${SELECTED_KUBECONFIG//\"/}\n\n"

        export KUBECONFIG={{ .KUBECONFIG_FOLDER }}/${SELECTED_KUBECONFIG//\"/}
        kubectl get nodes

        code {{ .TEST_DIR }}/${release}.yaml

        gum confirm "Do you want to apply ${release}?" || exit 0

        echo "Apply: helmfile apply -f {{ .TEST_DIR }}/${release}.yaml"
        helmfile apply -f {{ .TEST_DIR }}/${release}.yaml

        for i in {1..20}; do
          gum spin --spinner dot --title "Waiting for all pods to be running..." -- sleep 5
          kubectl get po -A | grep -v "kube-system" | grep -v "Completed"
          kubectl get ingress -A

          choice=$(gum choose "SKIP WAITING" "CONTINUE WAITING")
          if [[ "$choice" == "SKIP WAITING" ]]; then
            echo "Skipping loop."
            break
          fi
        done

        # POST CONFIG
        #if $(yq e ".template.${release}" {{ .POST_CONFIG_FILES }}) != "null"; then
        #  echo Key ${release} found
        #fi

        gum confirm "Do you want to destroy ${release}?" || exit 0
        helmfile destroy -f {{ .TEST_DIR }}/${release}.yaml
    vars:
      KUBECONFIG_FOLDER: ~/.kube
      SEARCH_FOLDERS: "infra apps database cicd"
      ALL_KUBECONFIGS:
        sh: ls {{ .KUBECONFIG_FOLDER }} | grep -v "^cache$" | xargs -n1 printf '"%s" '

  uninstall-release:
    desc: Uninstall a release
    cmds:
      - |
        SELECTED_KUBECONFIG=$(gum choose {{ .ALL_KUBECONFIGS }})
        echo SWITCHING TO ${SELECTED_KUBECONFIG//\"/}
        printf "\n\nexport KUBECONFIG={{ .KUBECONFIG_FOLDER }}/${SELECTED_KUBECONFIG//\"/}\n\n"

        export KUBECONFIG={{ .KUBECONFIG_FOLDER }}/${SELECTED_KUBECONFIG//\"/}
        kubectl get nodes

        ALL_HELM_RELEASES=$(helm ls -A | awk 'NR>1 {print $1 ":" $2}')
        echo ${ALL_HELM_RELEASES}

        SELECTED_RELEASE=$(echo "$ALL_HELM_RELEASES" | gum choose)

        # Extract release name and namespace
        RELEASE_NAME=$(echo "$SELECTED_RELEASE" | cut -d':' -f1)
        NAMESPACE=$(echo "$SELECTED_RELEASE" | cut -d':' -f2)

        # Uninstall the Helm release
        helm uninstall "$RELEASE_NAME" -n "$NAMESPACE"


    vars:
      KUBECONFIG_FOLDER: ~/.kube
      ALL_KUBECONFIGS:
        sh: ls {{ .KUBECONFIG_FOLDER }} | grep -v "^cache$" | xargs -n1 printf '"%s" '





  execute-base-cluster-setup:
    desc: Execute base setup on kind cluster
    vars:
      RANDOM:
        sh: |
          echo $RANDOM % 5555 + 1 | bc
    env:
      HELMFILE_CACHE_HOME: /tmp/helmfile/cache/{{ .DATE }}/{{ .RANDOM }}
      KUBECONFIG: "{{ .PATH_KUBE_CONFIG }}"
    cmds:
      - |
        gum confirm "Do you want to execute base cluster setup on {{ .CLUSTER_NAME }}?" || exit 0

        machineshop render \
        --source local \
        --template {{ .PATH_CLUSTER_TEMPLATE }} \
        --output file \
        --kind multikey \
        --key kind-infra \
        --destination {{ .CLUSTER_INFRA_HELMFILE }} \
        --values "source={{ .USER_WORKING_DIR }},clusterName={{ .CLUSTER_NAME }}"

        START_TIME=$(date +%s)
        TIMEOUT=180 # seconds

        helmfile init

        while true; do

          echo "RUNNING HELMFILE APPLY..."
          helmfile apply -f {{ .CLUSTER_INFRA_HELMFILE }} --kubeconfig {{ .PATH_KUBE_CONFIG }} && \
          echo "RUNNING HELMFILE SYNC..." && \
          helmfile sync -f {{ .CLUSTER_INFRA_HELMFILE }} --kubeconfig {{ .PATH_KUBE_CONFIG }} && \
          { echo "Commands succeeded. Exiting loop."; break; }

          CURRENT_TIME=$(date +%s)
          ELAPSED=$(( CURRENT_TIME - START_TIME ))

          if [ $ELAPSED -ge ${TIMEOUT} ]; then
            echo "COMMANDS ARE STILL FAILING AFTER ONE MINUTE. EXITING WITH ERROR."
            exit 1
          fi

          echo "RETRYING IN 5 SECONDS..."
          sleep 5

        done

        kubectl get po -A --kubeconfig {{ .PATH_KUBE_CONFIG }}

  destroy-kind-cluster:
    desc: Destroy kind cluster
    env:
      KUBECONFIG: "{{ .PATH_KUBE_CONFIG }}"
    cmds:
      - |
        if kind get clusters | grep -wq "{{ .CLUSTER_NAME }}"; then

          kubectl get nodes -o wide --kubeconfig {{ .PATH_KUBE_CONFIG }}

          # DELETE EXISTING CLUSTER
          gum confirm "Do you want to destroy existing cluster {{ .CLUSTER_NAME }}?" || exit 0
          echo "Cluster '{{ .CLUSTER_NAME }}' exists (already). Deleting it..."
          kind delete clusters "{{ .CLUSTER_NAME }}"

        fi

  create-kind-cluster:
    desc: Create, Start & Configure kind cluster
    env:
      KUBECONFIG: "{{ .PATH_KUBE_CONFIG }}"
    cmds:
      - task: destroy-kind-cluster
      - |
        touch {{ .KIND_CONFIG_PATH }}
        cat {{ .KIND_CONFIG_PATH }}
        gum confirm "Do you want to create cluster {{ .CLUSTER_NAME }}?" || exit 0

        K8S_VERSION=$(gum input --placeholder "Kubernetes version" --value "v1.32.2")

        # CREATE NEW CLUSTER
        machineshop render \
        --source local \
        --template {{ .PATH_CLUSTER_TEMPLATE }} \
        --output file \
        --values "clusterName={{ .CLUSTER_NAME }}, k8sVersion=${K8S_VERSION}" \
        --kind multikey \
        --key kind \
        --destination {{ .KIND_CONFIG_PATH }}

        kind create cluster --config {{ .KIND_CONFIG_PATH }} --name {{ .CLUSTER_NAME }} --kubeconfig {{ .PATH_KUBE_CONFIG }}
        kubectl get nodes
      - task: execute-base-cluster-setup
      - task: output-ingress-nipio

  output-ingress-nipio:
    desc: Output ingress domain
    env:
      KUBECONFIG: "{{ .PATH_KUBE_CONFIG }}"
    cmds:
      - |
        echo *.$(kubectl get nodes -o json | jq -r '.items[] | select(.metadata.labels."ingress-ready" == "true") | .status.addresses[] | select(.type == "InternalIP") | .address').nip.io

  check:
    desc: "Run pre-commit hooks"
    cmds:
      - pre-commit run -a

  # k3d:
  #   desc: Create, Start & Configure k3d cluster
  #   cmds:
  #     - |
  #       if k3d cluster list --no-headers | grep -wq "{{ .CLUSTER_NAME }}"; then
  #         echo "Cluster '{{ .CLUSTER_NAME }}' exists (already). Deleting it..."
  #         k3d cluster delete "{{ .CLUSTER_NAME }}"
  #       else
  #         echo "Cluster '{{ .CLUSTER_NAME }}' does not exist."
  #       fi
  #     - rm -rf {{ .DEV_CLUSTER_DIR }}/* && mkdir {{ .DEV_CLUSTER_DIR }} || true
  #     - |
  #       machineshop render \
  #       --source local \
  #       --template {{ .DEV_CLUSTER }} \
  #       --output file \
  #       --values "clusterName={{ .CLUSTER_NAME }}" \
  #       --kind multikey \
  #       --key cluster \
  #       --destination {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}.yaml
  #     - k3d cluster create --config {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}.yaml
  #     - k3d kubeconfig get {{ .CLUSTER_NAME }} > ~/.kube/{{ .CLUSTER_NAME }}
  #     - |
  #       SUBNET=$({{ .CONTAINER_RUNTIME }} network inspect k3d-{{ .CLUSTER_NAME }} | grep -oP '(?<="Subnet": ")[^"]+')
  #       BASE_IP=$(echo $SUBNET | cut -d'.' -f1-2)
  #       START_IP="${BASE_IP}.255.200"
  #       END_IP="${BASE_IP}.255.250"
  #       IP_RANGE="${START_IP}-${END_IP}"
  #       echo "${IP_RANGE}"

  #       machineshop render \
  #       --source local \
  #       --template {{ .DEV_CLUSTER }} \
  #       --output file \
  #       --kind multikey \
  #       --key ip \
  #       --destination {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ip.yaml \
  #       --values "source={{ .USER_WORKING_DIR }},ipRange=${IP_RANGE}"

  #       machineshop render \
  #       --source local \
  #       --template {{ .DEV_CLUSTER }} \
  #       --output file \
  #       --kind multikey \
  #       --key ingress \
  #       --destination {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ingress.yaml \
  #       --values "source={{ .USER_WORKING_DIR }},ipRange=${IP_RANGE}"


  #     #- helmfile template -f {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ip.yaml
  #     - helmfile apply -f {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ip.yaml || true
  #     - helmfile sync -f {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ip.yaml || true

  #     #- helmfile template -f {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ingress.yaml
  #     - helmfile apply -f {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-ingress.yaml

  #     # - helmfile template -f {{ .DEV_CLUSTER_DIR }}/{{ .CLUSTER_NAME }}-infra.yaml > {{ .DEV_CLUSTER_DIR }}/rendered.yaml --include-crds
  #     # - |
  #     #   kubectl --kubeconfig ~/.kube/{{ .CLUSTER_NAME }} create ns metallb-system
  #     #   kubectl --kubeconfig ~/.kube/{{ .CLUSTER_NAME }} create ns ingress-nginx
  #     #   kubectl --kubeconfig ~/.kube/{{ .CLUSTER_NAME }} create ns cert-manager
  #     # - kubectl apply --kubeconfig ~/.kube/{{ .CLUSTER_NAME }} -f {{ .DEV_CLUSTER_DIR }}/rendered.yaml || true
  #     # - sleep 15 && kubectl apply --kubeconfig ~/.kube/{{ .CLUSTER_NAME }} -f {{ .DEV_CLUSTER_DIR }}/rendered.yaml || true
  #   vars:
  #     CONTAINER_RUNTIME: docker
  #     CLUSTER_CONFIG_DIR: /tests
  #     CLUSTER_NAME: k3d-dev

  switch-remote:
    desc: Switch to remote branch
    cmds:
      - |
        git fetch
        branches=($(git branch -r | grep -v 'origin/HEAD' | sed 's|origin/||'))
        branch=$(printf "%s\n" "${branches[@]}" | gum choose)
        git switch -c ${branch} --track origin/${branch}
        git branch && git status

  switch-local:
    desc: Switch to local branch
    cmds:
      - |
        branches=$(git branch -a | grep -v 'remotes')
        branch=$(printf "%s\n" "${branches[@]}" | gum choose)
        git checkout ${branch} && git pull

  # uninstall-release:
  #   desc: Uninstall release
  #   cmds:
  #     - |
  #       SELECTED_KUBECONFIG=$(gum choose {{ .ALL_KUBECONFIGS }})
  #       echo SWITCHING TO ${SELECTED_KUBECONFIG//\"/}
  #       printf "\n\nexport KUBECONFIG={{ .KUBECONFIG_FOLDER }}/${SELECTED_KUBECONFIG//\"/}\n\n"

  #       export KUBECONFIG={{ .KUBECONFIG_FOLDER }}/${SELECTED_KUBECONFIG//\"/}
  #       kubectl get nodes
  #   vars:
  #     KUBECONFIG_FOLDER: ~/.kube
  #     ALL_KUBECONFIGS:
  #       sh: ls {{ .KUBECONFIG_FOLDER }} | xargs -n1 printf '"%s" '


  tests-create-includes:
    desc: Create test files
    cmds:
      - rm -rf {{ .TEST_DIR }}/* && mkdir {{ .TEST_DIR }} || true
      - |
        mkdir -p {{ .RENDER_DIR }}

        for release in $(yq '.template | keys | .[]' {{ .TEST_FILES }}); do

          echo "Creating: ${release} include"

            folder=$(find {{ .SEARCH_FOLDERS }} -type f -name "${release}.yaml" -exec dirname {} \; | sort -u)
            clusterIssuer=$(kubectl get clusterissuer -o jsonpath='{.items[0].metadata.name}')
            storageClass=standard

            machineshop render \
            --source local \
            --template {{ .TEST_RELEASE_TEMPLATES }} \
            --output file \
            --kind multikey \
            --key ${release} \
            --destination {{ .RENDER_DIR }}/${release}.yaml \
            --defaults {{ .TEST_DEFAULTS }} \
            --values "source={{ .USER_WORKING_DIR }}/${folder}/${release}.yaml"

            helmfile template -f {{ .RENDER_DIR }}/${release}.yaml

        done
    vars:
      RENDER_DIR: "/tmp/{{ .DATE }}"

  tests-render-includes:
    desc: Test render includes
    cmds:
      - task: tests-create-includes
      - |
        for release in $(yq '.template | keys | .[]' {{ .TEST_FILES }}); do

          echo "Rendering: ${release}"
          export HELMFILE_CACHE_HOME={{ .TEST_DIR }}/cache
          helmfile deps -f {{ .TEST_DIR }}/${release}.yaml
          helmfile template -f {{ .TEST_DIR }}/${release}.yaml

        done

  branch:
    desc: Create branch from main
    cmds:
      - git checkout main
      - git branch
      - git pull
      - |
        echo "Enter to be created (remote) branch:"
        read BRANCH_NAME;
        git checkout -b ${BRANCH_NAME}
        git push origin ${BRANCH_NAME}
      - git branch
      - git branch --set-upstream-to=origin/main ${BRANCH_NAME}

  run-pre-commit-hook:
    deps:
      - check
    desc: "Run the pre-commit hook script to replace .example.com with .example.com"
    cmds:
      - |
        # Find all YAML files in the repository recursively, excluding Taskfile.yaml
        files=$(find . -type f \( -name "*.yaml" -o -name "*.yml" -o -name "*.yml" -o -name "*.md" \) ! -name "Taskfile.yaml")

        # Loop through each file
        for file in $files; do
          # Skip binary files
          if file "$file" | grep -q "text"; then
            # Replace the string and update the file
            sed -i 's/\.sva\.de/\.example\.com/g' "$file"
          fi
        done

        # Add all modified YAML files back to staging
        git add $(git ls-files --modified | grep -E '\.ya?ml$')

        exit 0
    silent: false

  commit:
    desc: Commit + push code into branch
    deps:
      - check
    cmds:
      - git branch --set-upstream-to=origin/{{ .BRANCH }}
      - git pull
      - git status
      - |
        git add *
        git status
        if [[ -n $(git status --porcelain) ]]; then
          echo "Review the changes above."
          gum confirm "Do you want to commit these changes?" || exit 0

          echo "ENTER COMMIT MESSAGE"
          COMMIT_MESSAGE=$(gum choose "CUSTOM MESSAGE" "feat: {{ .BRANCH }}" "fix: {{ .BRANCH }}" "BREAKING CHANGE: {{ .BRANCH }}")

          if [ "$COMMIT_MESSAGE" == "CUSTOM MESSAGE" ]; then
            CHANGED_FILES=$(git status --short | awk '{print $2}' | tr '\n' ' ')
            COMMIT_MESSAGE=$(gum input --placeholder "Commit message" --value "Changed: $CHANGED_FILES")
          fi

          git commit --allow-empty -a -m "$COMMIT_MESSAGE"
        else
          echo "No changes to commit."
        fi
      - git push origin -u {{ .BRANCH }}

  pr:
    desc: Create pull request into main
    cmds:
      - task: commit
      - gh pr create -t "{{ .BRANCH }}" -b "{{ .BRANCH }} branch into main"
      - sleep 2s
      # - gh pr checks $(gh pr list | grep "^[^#;]" | awk '{print $1}') --watch
      - gh pr merge $(gh pr list | grep "^[^#;]" | grep '{{ .BRANCH }}' | awk '{print $1}') --auto --rebase --delete-branch
      - git checkout main && git pull

  release:
    deps:
      - check
    desc: push new version
    cmds:
      - task: pr
      - npx semantic-release --dry-run
      - npx semantic-release --debug --no-ci
      - echo released version $(git describe --tags --abbrev=0)
